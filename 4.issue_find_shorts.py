#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from playwright.sync_api import sync_playwright
import json
import pandas as pd
from datetime import datetime
import re


def clean_text(text):
    """í…ìŠ¤íŠ¸ ì •ë¦¬ - íŠ¹ìˆ˜ë¬¸ì ì œê±°, ê³µë°± ì •ë¦¬"""
    if not text:
        return ""
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def classify_humor_category(title, category=""):
    """
    ìœ ë¨¸ ê²Œì‹œë¬¼ì„ ì„¸ë¶€ ë¶„ì•¼ë¡œ ë¶„ë¥˜

    ë¶„ë¥˜:
    - ì¼ìƒìœ ë¨¸: ì¼ìƒìƒí™œ, ê²½í—˜ë‹´
    - ì§¤ë°©/ì›€ì§¤: ì´ë¯¸ì§€, GIF, ì‚¬ì§„
    - ë“œë¦½/ë§ì¥ë‚œ: ì–¸ì–´ìœ í¬, ë§ì¥ë‚œ
    - ë™ë¬¼: ê³ ì–‘ì´, ê°•ì•„ì§€, ë™ë¬¼
    - ì—°ì˜ˆ/ë°©ì†¡: ì—°ì˜ˆì¸, TV, ì˜í™”
    - ê²Œì„: ê²Œì„ ê´€ë ¨
    - ìŠ¤í¬ì¸ : ì¶•êµ¬, ì•¼êµ¬, ìŠ¤í¬ì¸ 
    - ì‹œì‚¬íŒ¨ëŸ¬ë””: ì‹œì‚¬, ì •ì¹˜ íŒ¨ëŸ¬ë””
    - ì°/í›„ê¸°: ê²½í—˜ë‹´, í›„ê¸°
    - ê¸°íƒ€ìœ ë¨¸: ë¶„ë¥˜ë˜ì§€ ì•ŠëŠ” ìœ ë¨¸
    """

    title_lower = title.lower()
    category_lower = category.lower()
    combined = (title + " " + category).lower()

    # ê° ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì •ì˜
    categories = {
        'ë™ë¬¼': ['ê³ ì–‘ì´', 'ê°•ì•„ì§€', 'ëƒ¥ì´', 'ë©ë©ì´', 'ë°˜ë ¤ë™ë¬¼', 'í«', 'pet', 'ëƒ¥', 'ë©', 'ë™ë¬¼', 'ìƒˆ', 'í–„ìŠ¤í„°'],
        'ì§¤ë°©/ì›€ì§¤': ['ì§¤', 'ì›€ì§¤', 'gif', 'ì‚¬ì§„', 'ì´ë¯¸ì§€', 'ì¸ì¦', 'ì›€ì§ì´ëŠ”', 'ì‚¬ì§„ì²©', 'ê°¤ëŸ¬ë¦¬'],
        'ê²Œì„': ['ê²Œì„', 'ë¡¤', 'lol', 'ë¦¬ê·¸ì˜¤ë¸Œë ˆì „ë“œ', 'ë°°ê·¸', 'ì˜¤ë²„ì›Œì¹˜', 'ìŠ¤íŒ€', 'pcë°©', 'ëª¨ë°”ì¼ê²Œì„', 'ê²œ'],
        'ì—°ì˜ˆ/ë°©ì†¡': ['ì—°ì˜ˆì¸', 'ì•„ì´ëŒ', 'ë°°ìš°', 'ë°©ì†¡', 'tv', 'ë“œë¼ë§ˆ', 'ì˜í™”', 'ì˜ˆëŠ¥', 'ë„·í”Œë¦­ìŠ¤', 'ìœ íŠœë²„', 'ìŠ¤íŠ¸ë¦¬ë¨¸'],
        'ìŠ¤í¬ì¸ ': ['ì•¼êµ¬', 'ì¶•êµ¬', 'ë†êµ¬', 'ë°°êµ¬', 'ì†í¥ë¯¼', 'ë©”ì‹œ', 'í˜¸ë‚ ë‘', 'ìŠ¤í¬ì¸ ', 'ìš´ë™', 'ì˜¬ë¦¼í”½'],
        'ì°/í›„ê¸°': ['ì°', 'í›„ê¸°', 'ê²½í—˜ë‹´', 'ì‹¤í™”', 'ìˆì—ˆë˜', 'ê²ªì€', 'ë‹¹í•œ', 'ë§Œë‚œ', 'ã„¹ã…‡', 'ë ˆì „ë“œ'],
        'ë“œë¦½/ë§ì¥ë‚œ': ['ë“œë¦½', 'ë§ì¥ë‚œ', 'ì–¸ì–´ìœ í¬', 'ì´ë¦„ë“œë¦½', 'ê°œë“œë¦½', 'ì•„ì¬ê°œê·¸', 'ã…‹ã…‹', 'ã…ã…'],
        'ì‹œì‚¬íŒ¨ëŸ¬ë””': ['ì‹œì‚¬', 'ë‰´ìŠ¤', 'ì •ì¹˜', 'ëŒ€í†µë ¹', 'êµ­íšŒ', 'ì •ë¶€', 'íŒ¨ëŸ¬ë””', 'í’ì'],
        'ì¼ìƒìœ ë¨¸': ['ì¼ìƒ', 'ì§ì¥', 'íšŒì‚¬', 'í•™êµ', 'ì•Œë°”', 'í¸ì˜ì ', 'ì¹´í˜', 'ìŒì‹', 'ìš”ë¦¬', 'ë§›ì§‘']
    }

    # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë¶„ë¥˜
    for cat_name, keywords in categories.items():
        for keyword in keywords:
            if keyword in combined:
                return cat_name

    return 'ê¸°íƒ€ìœ ë¨¸'


def is_shorts_suitable(title, content=""):
    """
    ì‡¼ì¸  ì œì‘ì— ì í•©í•œ ì£¼ì œì¸ì§€ íŒë‹¨

    ì í•© ê¸°ì¤€:
    - í¥ë¯¸ë¡œìš´ ì´ìŠˆ (ë…¼ë€, í™”ì œ)
    - ì‹œê°ì  í‘œí˜„ ê°€ëŠ¥ (ì‚¬ì§„/ì˜ìƒ ê´€ë ¨)
    - ê°ì •ì  ë°˜ì‘ ìœ ë°œ (ì›ƒê¹€, ê°ë™, ë†€ë¼ì›€)
    - ì •ë³´ì„± (ê¿€íŒ, ì‹ ê¸°í•œ ì‚¬ì‹¤)
    """

    # ì œì™¸í•  í‚¤ì›Œë“œ (ê´‘ê³ ì„±, ìŠ¤íŒ¸ì„±, ë¯¼ê°í•œ ì •ì¹˜ ë“±)
    exclude_keywords = [
        'ê´‘ê³ ', 'í™ë³´', 'êµ¬ë§¤', 'íŒë§¤', 'ì•Œë°”', 'ëª¨ì§‘',
        'í˜ì˜¤', 'ë¹„í•˜', 'ìš•ì„¤', 'ì„ ì •ì '
    ]

    # í¬í•¨í•˜ë©´ ì¢‹ì€ í‚¤ì›Œë“œ (ì‡¼ì¸  ì í•©)
    include_keywords = [
        'ì°', 'í›„ê¸°', 'ë ˆì „ë“œ', 'ì‹¤í™”', 'ã„·ã„·', 'ã…‹ã…‹',
        'ë†€ë¼ìš´', 'ì‹ ê¸°í•œ', 'ëŒ€ë°•', 'ì¶©ê²©', 'í™”ì œ',
        'ìµœê·¼', 'ìš”ì¦˜', 'ê·¼í™©', 'TMI', 'íŒ', 'ê¿€íŒ',
        'ë°˜ì‘', 'ì¸ê¸°', 'HOT', 'ë² ìŠ¤íŠ¸', 'ê°œë…ê¸€',
        'ì‚¬ì§„', 'ì˜ìƒ', 'gif', 'ì›€ì§¤'
    ]

    title_lower = title.lower()

    # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
    for keyword in exclude_keywords:
        if keyword in title:
            return False

    # í¬í•¨ í‚¤ì›Œë“œ ì²´í¬ (ê°€ì¤‘ì¹˜)
    score = 0
    for keyword in include_keywords:
        if keyword in title or keyword in title_lower:
            score += 1

    # ì´ëª¨í‹°ì½˜ì´ë‚˜ íŠ¹ìˆ˜ë¬¸ìê°€ ë§ìœ¼ë©´ ê°ì • í‘œí˜„ì´ ìˆë‹¤ê³  íŒë‹¨
    emoji_count = len(re.findall(r'[ã…‹ã…ã„·ã„¹ã…‡!?]', title))
    if emoji_count >= 2:
        score += 1

    # ì œëª© ê¸¸ì´ê°€ ì ë‹¹í•˜ë©´ ê°€ì‚°ì 
    if 10 <= len(title) <= 50:
        score += 1

    return score >= 2


def scrape_dcinside():
    """
    DCì¸ì‚¬ì´ë“œ ê°œë…ê¸€/ì‹¤ë²  ìŠ¤í¬ë˜í•‘
    """
    print("\nğŸ” DCì¸ì‚¬ì´ë“œ ìŠ¤í¬ë˜í•‘ ì‹œì‘...")

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        issues = []

        try:
            # ë©”ì¸ í˜ì´ì§€ ì ‘ì†
            page.goto('https://gall.dcinside.com/', wait_until='networkidle', timeout=30000)
            page.wait_for_timeout(2000)

            # ê°œë…ê¸€ ì œëª© ì¶”ì¶œ
            titles = page.locator('strong.tit').all()

            for idx, title_elem in enumerate(titles[:30]):  # ìµœëŒ€ 30ê°œ
                try:
                    title = clean_text(title_elem.inner_text())

                    if not title or len(title) < 5:
                        continue

                    # ë¶€ëª¨ ìš”ì†Œì—ì„œ ê°¤ëŸ¬ë¦¬ëª…ê³¼ ë‚ ì§œ ì°¾ê¸°
                    parent = title_elem.locator('xpath=../..').first

                    gallery = ""
                    date = ""

                    # info divì—ì„œ ê°¤ëŸ¬ë¦¬ëª…ê³¼ ë‚ ì§œ ì¶”ì¶œ
                    info_divs = parent.locator('.info span').all()
                    if len(info_divs) >= 2:
                        gallery = clean_text(info_divs[0].inner_text())
                        date = clean_text(info_divs[1].inner_text())

                    # ë§í¬ ì¶”ì¶œ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
                    link = ""

                    # ë°©ë²• 1: titleì„ í¬í•¨í•œ a íƒœê·¸ ì°¾ê¸°
                    title_parent_link = title_elem.locator('xpath=ancestor::a').first
                    if title_parent_link.count() > 0:
                        href = title_parent_link.get_attribute('href')
                        if href:
                            if href.startswith('http'):
                                link = href
                            elif href.startswith('/'):
                                link = 'https://gall.dcinside.com' + href

                    # ë°©ë²• 2: parentì˜ a íƒœê·¸ ì°¾ê¸°
                    if not link:
                        link_elem = parent.locator('a').first
                        if link_elem.count() > 0:
                            href = link_elem.get_attribute('href')
                            if href:
                                if href.startswith('http'):
                                    link = href
                                elif href.startswith('/'):
                                    link = 'https://gall.dcinside.com' + href

                    issue = {
                        'platform': 'DCì¸ì‚¬ì´ë“œ',
                        'category': gallery,
                        'title': title,
                        'date': date,
                        'link': link,
                        'shorts_suitable': is_shorts_suitable(title),
                        'humor_category': classify_humor_category(title, gallery),
                        'scraped_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    }

                    issues.append(issue)

                except Exception as e:
                    print(f"  âš ï¸  ê°œë³„ í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

            print(f"âœ… DCì¸ì‚¬ì´ë“œ: {len(issues)}ê°œ ì´ìŠˆ ë°œê²¬")

        except Exception as e:
            print(f"âŒ DCì¸ì‚¬ì´ë“œ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")

        finally:
            browser.close()

        return issues


def scrape_fmkorea():
    """
    FM Korea ë² ìŠ¤íŠ¸ ê²Œì‹œë¬¼ ìŠ¤í¬ë˜í•‘
    """
    print("\nğŸ” FM Korea ìŠ¤í¬ë˜í•‘ ì‹œì‘...")

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        issues = []

        try:
            # ë² ìŠ¤íŠ¸ í˜ì´ì§€ ì ‘ì†
            page.goto('https://www.fmkorea.com/best', wait_until='networkidle', timeout=30000)
            page.wait_for_timeout(2000)

            # ê²Œì‹œë¬¼ ëª©ë¡ ì¶”ì¶œ
            articles = page.locator('.li_best_wrapper, .fm_best_widget li, article').all()

            for idx, article in enumerate(articles[:30]):  # ìµœëŒ€ 30ê°œ
                try:
                    # ì œëª© ë° ë§í¬ ì¶”ì¶œ (ì—¬ëŸ¬ ì„ íƒì ì‹œë„)
                    title = ""
                    link = ""
                    title_selectors = [
                        '.title a',
                        'a.hx',
                        '.hotdeal_title a',
                        'a[href*="/board/"]',
                        'a[href*="/hot/"]'
                    ]

                    title_link_elem = None
                    for selector in title_selectors:
                        elem = article.locator(selector).first
                        if elem.count() > 0:
                            title = clean_text(elem.inner_text())
                            if title and len(title) >= 5:
                                title_link_elem = elem
                                break

                    if not title or len(title) < 5:
                        continue

                    # ì œëª© ìš”ì†Œì—ì„œ ë§í¬ ì¶”ì¶œ
                    if title_link_elem:
                        href = title_link_elem.get_attribute('href')
                        if href:
                            if href.startswith('http'):
                                link = href
                            elif href.startswith('/'):
                                link = 'https://www.fmkorea.com' + href

                    # ë§í¬ê°€ ì—†ìœ¼ë©´ articleì˜ ì²« ë²ˆì§¸ a íƒœê·¸ì—ì„œ ì¶”ì¶œ
                    if not link:
                        link_elem = article.locator('a').first
                        if link_elem.count() > 0:
                            href = link_elem.get_attribute('href')
                            if href:
                                if href.startswith('http'):
                                    link = href
                                elif href.startswith('/'):
                                    link = 'https://www.fmkorea.com' + href

                    # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
                    category = "ë² ìŠ¤íŠ¸"
                    category_elem = article.locator('.category, .category_wrapper').first
                    if category_elem.count() > 0:
                        category = clean_text(category_elem.inner_text())

                    # ë‚ ì§œ ì¶”ì¶œ
                    date = ""
                    date_elem = article.locator('.date, .time, .regdate').first
                    if date_elem.count() > 0:
                        date = clean_text(date_elem.inner_text())

                    issue = {
                        'platform': 'FM Korea',
                        'category': category,
                        'title': title,
                        'date': date,
                        'link': link,
                        'shorts_suitable': is_shorts_suitable(title),
                        'humor_category': classify_humor_category(title, category),
                        'scraped_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    }

                    issues.append(issue)

                except Exception as e:
                    print(f"  âš ï¸  ê°œë³„ í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

            print(f"âœ… FM Korea: {len(issues)}ê°œ ì´ìŠˆ ë°œê²¬")

        except Exception as e:
            print(f"âŒ FM Korea ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")

        finally:
            browser.close()

        return issues


def select_platform():
    """
    ì‚¬ìš©ìê°€ í”Œë«í¼ì„ ì„ íƒí•˜ë„ë¡ í•¨
    """
    print("\n" + "="*60)
    print("ğŸ“± ì‡¼ì¸  ì œì‘ìš© ì´ìŠˆ ì°¾ê¸°")
    print("="*60)
    print("\nì»¤ë®¤ë‹ˆí‹° í”Œë«í¼ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. DCì¸ì‚¬ì´ë“œ")
    print("2. FM Korea")
    print("3. ì „ì²´ (ëª¨ë“  í”Œë«í¼)")
    print("="*60)

    while True:
        choice = input("\nì„ íƒ (1-3): ").strip()

        if choice == '1':
            return ['dcinside']
        elif choice == '2':
            return ['fmkorea']
        elif choice == '3':
            return ['dcinside', 'fmkorea']
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1-3 ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")


def main():
    # í”Œë«í¼ ì„ íƒ
    platforms = select_platform()

    all_issues = []

    # ì„ íƒí•œ í”Œë«í¼ë³„ ìŠ¤í¬ë˜í•‘
    for platform in platforms:
        if platform == 'dcinside':
            issues = scrape_dcinside()
        elif platform == 'fmkorea':
            issues = scrape_fmkorea()
        else:
            continue

        all_issues.extend(issues)

    if not all_issues:
        print("\nâŒ ìˆ˜ì§‘ëœ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì‡¼ì¸  ì í•©í•œ ì£¼ì œë§Œ í•„í„°ë§
    suitable_issues = [issue for issue in all_issues if issue['shorts_suitable']]

    print(f"\nğŸ“Š ì´ {len(all_issues)}ê°œ ì´ìŠˆ ì¤‘ {len(suitable_issues)}ê°œê°€ ì‡¼ì¸  ì œì‘ì— ì í•©í•©ë‹ˆë‹¤.")

    # ìœ ë¨¸ ë¶„ì•¼ë³„ë¡œ ê·¸ë£¹í™”
    from collections import defaultdict
    humor_by_category = defaultdict(list)

    for issue in suitable_issues:
        humor_cat = issue.get('humor_category', 'ê¸°íƒ€ìœ ë¨¸')
        humor_by_category[humor_cat].append(issue)

    # ê° ë¶„ì•¼ë³„ TOP 10 ì¶”ì¶œ
    category_top10 = {}
    print("\nğŸ­ ìœ ë¨¸ ë¶„ì•¼ë³„ TOP 10:")
    print("="*80)

    for cat_name in sorted(humor_by_category.keys()):
        issues_in_cat = humor_by_category[cat_name]
        top10 = issues_in_cat[:10]
        category_top10[cat_name] = top10

        print(f"\nã€{cat_name}ã€‘ ({len(issues_in_cat)}ê°œ ì¤‘ ìƒìœ„ {len(top10)}ê°œ)")
        print("-"*80)

        for idx, issue in enumerate(top10, 1):
            print(f"{idx}. {issue['title'][:60]}")
            print(f"   ğŸ“° {issue['platform']} - {issue['category']}")
            if issue.get('link'):
                print(f"   ğŸ”— {issue['link']}")

    # ì „ì²´ ìƒìœ„ 10ê°œ ì„ íƒ (ì‡¼ì¸  ì í•©í•œ ê²ƒ ìš°ì„ )
    top_10_suitable = suitable_issues[:10] if len(suitable_issues) >= 10 else suitable_issues

    # ë¶€ì¡±í•˜ë©´ ì „ì²´ì—ì„œ ì±„ì›€
    if len(top_10_suitable) < 10:
        remaining = [issue for issue in all_issues if not issue['shorts_suitable']]
        needed = 10 - len(top_10_suitable)
        top_10_suitable.extend(remaining[:needed])

    print(f"\n\nğŸ¯ ì „ì²´ ì‡¼ì¸  ì œì‘ ì¶”ì²œ ì£¼ì œ TOP {len(top_10_suitable)}:")
    print("="*80)

    for idx, issue in enumerate(top_10_suitable, 1):
        suitable_mark = "â­" if issue['shorts_suitable'] else "  "
        humor_cat = issue.get('humor_category', 'ë¯¸ë¶„ë¥˜')
        print(f"\n{idx}. {suitable_mark} [{humor_cat}] {issue['category']}")
        print(f"   ğŸ“Œ ì œëª©: {issue['title']}")
        print(f"   ğŸ“° ì¶œì²˜: {issue['platform']}")
        print(f"   ğŸ”— ë§í¬: {issue.get('link', 'ë§í¬ ì—†ìŒ')}")
        if issue.get('date'):
            print(f"   ğŸ“… ë‚ ì§œ: {issue['date']}")

    # ê²°ê³¼ ì €ì¥
    date_str = datetime.now().strftime('%Y%m%d_%H%M%S')

    # JSON ì €ì¥ (ì „ì²´)
    json_filename = f'issues_all_{date_str}.json'
    with open(json_filename, 'w', encoding='utf-8') as f:
        json.dump(all_issues, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ ì „ì²´ ê²°ê³¼ê°€ '{json_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # JSON ì €ì¥ (ë¶„ì•¼ë³„ TOP 10)
    json_category_filename = f'issues_by_category_{date_str}.json'
    with open(json_category_filename, 'w', encoding='utf-8') as f:
        json.dump(category_top10, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ ë¶„ì•¼ë³„ TOP 10ì´ '{json_category_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ì—‘ì…€ ì €ì¥
    excel_filename = f'issues_{date_str}.xlsx'
    with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:
        # ì „ì²´ ì´ìŠˆ
        df_all = pd.DataFrame(all_issues)
        cols = ['platform', 'category', 'title', 'date', 'humor_category', 'shorts_suitable', 'link', 'scraped_at']
        cols = [c for c in cols if c in df_all.columns]
        df_all = df_all[cols]

        # ì»¬ëŸ¼ëª…ì„ í•œê¸€ë¡œ ë³€ê²½
        df_all = df_all.rename(columns={
            'platform': 'ì¶œì²˜',
            'category': 'ì¹´í…Œê³ ë¦¬',
            'title': 'ì œëª©',
            'date': 'ë‚ ì§œ',
            'humor_category': 'ìœ ë¨¸ë¶„ì•¼',
            'shorts_suitable': 'ì‡¼ì¸ ì í•©',
            'link': 'ë§í¬',
            'scraped_at': 'ìˆ˜ì§‘ì‹œê°„'
        })
        df_all.to_excel(writer, sheet_name='ì „ì²´', index=False)

        # ì „ì²´ TOP 10
        df_top10 = pd.DataFrame(top_10_suitable)
        top10_cols = [c for c in cols if c in df_top10.columns]
        df_top10 = df_top10[top10_cols]
        df_top10 = df_top10.rename(columns={
            'platform': 'ì¶œì²˜',
            'category': 'ì¹´í…Œê³ ë¦¬',
            'title': 'ì œëª©',
            'date': 'ë‚ ì§œ',
            'humor_category': 'ìœ ë¨¸ë¶„ì•¼',
            'shorts_suitable': 'ì‡¼ì¸ ì í•©',
            'link': 'ë§í¬',
            'scraped_at': 'ìˆ˜ì§‘ì‹œê°„'
        })
        df_top10.to_excel(writer, sheet_name='TOP10_ì „ì²´ì¶”ì²œ', index=False)

        # ê° ë¶„ì•¼ë³„ TOP 10 ì‹œíŠ¸ ìƒì„±
        for cat_name, cat_issues in category_top10.items():
            if cat_issues:
                df_cat = pd.DataFrame(cat_issues)
                cat_cols = [c for c in cols if c in df_cat.columns]
                df_cat = df_cat[cat_cols]
                df_cat = df_cat.rename(columns={
                    'platform': 'ì¶œì²˜',
                    'category': 'ì¹´í…Œê³ ë¦¬',
                    'title': 'ì œëª©',
                    'date': 'ë‚ ì§œ',
                    'humor_category': 'ìœ ë¨¸ë¶„ì•¼',
                    'shorts_suitable': 'ì‡¼ì¸ ì í•©',
                    'link': 'ë§í¬',
                    'scraped_at': 'ìˆ˜ì§‘ì‹œê°„'
                })
                # ì‹œíŠ¸ëª…ì—ì„œ ê¸ˆì§€ëœ ë¬¸ì ì œê±° (ì—‘ì…€ ì‹œíŠ¸ëª…ì— ì‚¬ìš© ë¶ˆê°€: : \ / ? * [ ])
                safe_name = cat_name.replace('/', '_').replace('\\', '_').replace(':', '_')
                safe_name = safe_name.replace('?', '').replace('*', '').replace('[', '').replace(']', '')
                # ì‹œíŠ¸ëª…ì€ 31ì ì œí•œì´ ìˆìœ¼ë¯€ë¡œ ì§§ê²Œ
                sheet_name = f"{safe_name[:20]}_TOP10"
                df_cat.to_excel(writer, sheet_name=sheet_name, index=False)

        # ì‡¼ì¸  ì í•© ì „ì²´
        if suitable_issues:
            df_suitable = pd.DataFrame(suitable_issues)
            suitable_cols = [c for c in cols if c in df_suitable.columns]
            df_suitable = df_suitable[suitable_cols]
            df_suitable = df_suitable.rename(columns={
                'platform': 'ì¶œì²˜',
                'category': 'ì¹´í…Œê³ ë¦¬',
                'title': 'ì œëª©',
                'date': 'ë‚ ì§œ',
                'humor_category': 'ìœ ë¨¸ë¶„ì•¼',
                'shorts_suitable': 'ì‡¼ì¸ ì í•©',
                'link': 'ë§í¬',
                'scraped_at': 'ìˆ˜ì§‘ì‹œê°„'
            })
            df_suitable.to_excel(writer, sheet_name='ì‡¼ì¸ ì í•©_ì „ì²´', index=False)

    print(f"ğŸ’¾ ì—‘ì…€ ê²°ê³¼ê°€ '{excel_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ë¶„ì•¼ë³„ í†µê³„ ì¶œë ¥
    print("\nğŸ“ˆ ìœ ë¨¸ ë¶„ì•¼ë³„ í†µê³„:")
    print("="*50)
    for cat_name in sorted(humor_by_category.keys()):
        count = len(humor_by_category[cat_name])
        print(f"  {cat_name}: {count}ê°œ")

    print("\nâœ¨ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
