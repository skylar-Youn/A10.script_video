"""
ë¶„ì„ ê´€ë ¨ API ë¼ìš°í„°
"""
import os
import logging
from fastapi import APIRouter, HTTPException, Body
from pathlib import Path

from ..config import DOWNLOAD_DIR
from ..services.audio_service import (
    analyze_audio_file, extract_audio_from_video, extract_waveform_data, audio_to_srt
)
from ..services.subtitle_service import (
    parse_srt_file, analyze_subtitle_timing, calculate_quality_score
)
from ..services.speaker_recognition import SpeakerRecognition
from ..services.audio_speaker_recognition import AudioSpeakerRecognition
from ..services.simple_audio_speaker_recognition import SimpleAudioSpeakerRecognition
from ..services.ai_reinterpretation import reinterpret_subtitles as ai_reinterpret_subtitles

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api", tags=["analysis"])


@router.post("/analyze-waveform")
async def analyze_audio_waveform(request: dict = Body(...)):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì˜ íŒŒí˜• ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë°˜í™˜"""
    try:
        audio_path = request.get("audio_path")
        width = request.get("width", 800)  # íŒŒí˜• ë„ˆë¹„ (í”½ì…€)

        if not audio_path or not os.path.exists(audio_path):
            raise HTTPException(status_code=404, detail="ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # FFmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒí˜• ë°ì´í„° ì¶”ì¶œ
        waveform_data = extract_waveform_data(audio_path, width)

        return {
            "status": "success",
            "audio_path": audio_path,
            "waveform_data": waveform_data,
            "width": width,
            "sample_count": len(waveform_data)
        }

    except Exception as e:
        logger.exception(f"íŒŒí˜• ë¶„ì„ ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analysis/audio")
async def analyze_audio(request: dict = Body(...)):
    """ìŒì„± íŒŒì¼ ë¶„ì„ - ë¬´ìŒ êµ¬ê°„, ë³¼ë¥¨ ë“±"""
    try:
        file_paths = request.get("files", [])
        options = request.get("options", {})

        silence_threshold = float(options.get("silence_threshold", 0.05))
        min_gap_duration = float(options.get("min_gap", 0.15))

        results = []

        for file_path in file_paths:
            try:
                if not os.path.exists(file_path):
                    results.append({
                        "file": file_path,
                        "status": "error",
                        "error": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                    })
                    continue

                # ë¹„ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° ì˜¤ë””ì˜¤ ì¶”ì¶œ
                temp_audio_path = None
                if file_path.endswith(('.mp4', '.webm', '.avi', '.mov')):
                    temp_audio_path = extract_audio_from_video(file_path)
                    audio_path = temp_audio_path
                else:
                    audio_path = file_path

                analysis_result = analyze_audio_file(audio_path, silence_threshold, min_gap_duration)

                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                if temp_audio_path and os.path.exists(temp_audio_path):
                    os.remove(temp_audio_path)

                results.append({
                    "file": file_path,
                    "status": "success",
                    "data": analysis_result
                })

            except Exception as e:
                logger.exception(f"ì˜¤ë””ì˜¤ ë¶„ì„ ì—ëŸ¬ - {file_path}: {e}")
                results.append({
                    "file": file_path,
                    "status": "error",
                    "error": str(e)
                })

        return {"results": results}

    except Exception as e:
        logger.exception(f"ë°°ì¹˜ ì˜¤ë””ì˜¤ ë¶„ì„ ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analysis/subtitle")
async def analyze_subtitle(request: dict = Body(...)):
    """SRT íŒŒì¼ ë¶„ì„ - ê°­, ê²¹ì¹¨, íƒ€ì´ë°"""
    try:
        file_paths = request.get("files", [])

        results = []

        for file_path in file_paths:
            try:
                if not os.path.exists(file_path):
                    results.append({
                        "file": file_path,
                        "status": "error",
                        "error": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                    })
                    continue

                if not file_path.endswith('.srt'):
                    results.append({
                        "file": file_path,
                        "status": "error",
                        "error": "SRT íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤"
                    })
                    continue

                subtitles = parse_srt_file(file_path)
                analysis_result = analyze_subtitle_timing(subtitles)

                # ìë§‰ êµ¬ê°„ ë°ì´í„°ë¥¼ dataì— í¬í•¨
                analysis_result["subtitles"] = subtitles

                results.append({
                    "file": file_path,
                    "status": "success",
                    "data": analysis_result
                })

            except Exception as e:
                logger.exception(f"ìë§‰ ë¶„ì„ ì—ëŸ¬ - {file_path}: {e}")
                results.append({
                    "file": file_path,
                    "status": "error",
                    "error": str(e)
                })

        return {"results": results}

    except Exception as e:
        logger.exception(f"ë°°ì¹˜ ìë§‰ ë¶„ì„ ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analysis/stt")
async def speech_to_text(request: dict = Body(...)):
    """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ SRT ìƒì„±"""
    try:
        file_paths = request.get("files", [])
        options = request.get("options", {})

        language = options.get("language", "ko-KR")
        segment_duration = int(options.get("segment_duration", 5))

        results = []

        for file_path in file_paths:
            try:
                if not os.path.exists(file_path):
                    results.append({
                        "file": file_path,
                        "status": "error",
                        "error": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                    })
                    continue

                # ë¹„ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° ì˜¤ë””ì˜¤ ì¶”ì¶œ
                temp_audio_path = None
                if file_path.endswith(('.mp4', '.webm', '.avi', '.mov')):
                    temp_audio_path = extract_audio_from_video(file_path)
                    audio_path = temp_audio_path
                else:
                    audio_path = file_path

                srt_result = audio_to_srt(audio_path, language, segment_duration)

                # SRT íŒŒì¼ ì €ì¥
                base_name = os.path.splitext(os.path.basename(file_path))[0]
                srt_path = DOWNLOAD_DIR / f"{base_name}_generated.srt"

                with open(srt_path, 'w', encoding='utf-8') as f:
                    f.write(srt_result["srt_content"])

                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                if temp_audio_path and os.path.exists(temp_audio_path):
                    os.remove(temp_audio_path)

                results.append({
                    "file": file_path,
                    "status": "success",
                    "data": {
                        **srt_result,
                        "output_path": str(srt_path)
                    }
                })

            except Exception as e:
                logger.exception(f"STT ë¶„ì„ ì—ëŸ¬ - {file_path}: {e}")
                results.append({
                    "file": file_path,
                    "status": "error",
                    "error": str(e)
                })

        return {"results": results}

    except Exception as e:
        logger.exception(f"ë°°ì¹˜ STT ë¶„ì„ ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analysis/compare")
async def compare_subtitles(request: dict = Body(...)):
    """ë‘ SRT íŒŒì¼ ë¹„êµ ë¶„ì„"""
    try:
        original_file = request.get("original_file")
        generated_file = request.get("generated_file")

        if not original_file or not generated_file:
            raise HTTPException(status_code=400, detail="ë‘ íŒŒì¼ ê²½ë¡œê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤")

        if not os.path.exists(original_file) or not os.path.exists(generated_file):
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        original_subtitles = parse_srt_file(original_file)
        generated_subtitles = parse_srt_file(generated_file)

        original_analysis = analyze_subtitle_timing(original_subtitles)
        generated_analysis = analyze_subtitle_timing(generated_subtitles)

        comparison_result = {
            "original": {
                "file": original_file,
                "analysis": original_analysis,
                "subtitles": original_subtitles[:10]
            },
            "generated": {
                "file": generated_file,
                "analysis": generated_analysis,
                "subtitles": generated_subtitles[:10]
            },
            "comparison": {
                "subtitle_count_diff": len(generated_subtitles) - len(original_subtitles),
                "duration_diff": generated_analysis["total_duration"] - original_analysis["total_duration"],
                "quality_score": calculate_quality_score(original_analysis, generated_analysis)
            }
        }

        return {
            "status": "success",
            "data": comparison_result
        }

    except Exception as e:
        logger.exception(f"ìë§‰ ë¹„êµ ë¶„ì„ ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analysis/speaker-recognition")
async def analyze_speakers(request: dict = Body(...)):
    """ìë§‰ì—ì„œ í™”ì ì¸ì‹ ë° ë¶„ë¥˜"""
    try:
        file_path = request.get("file_path")

        if not file_path or not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="SRT íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        if not file_path.endswith('.srt'):
            raise HTTPException(status_code=400, detail="SRT íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤")

        # SRT íŒŒì¼ íŒŒì‹±
        subtitles = parse_srt_file(file_path)

        # í™”ì ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        speaker_recognition = SpeakerRecognition()

        # í™”ì ê°ì§€
        detection_result = speaker_recognition.detect_speakers_from_subtitles(subtitles)

        return {
            "status": "success",
            "file": file_path,
            "speakers": detection_result["speakers"],
            "total_speakers": detection_result["total_speakers"],
            "patterns": detection_result["patterns"]
        }

    except Exception as e:
        logger.exception(f"í™”ì ì¸ì‹ ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analysis/assign-speakers-to-tracks")
async def assign_speakers_to_tracks(request: dict = Body(...)):
    """ì„ íƒëœ ì¸ë¬¼ì˜ ëŒ€ì‚¬ë¥¼ íŠ¹ì • íŠ¸ë™ì— ìë™ ë°°ì¹˜"""
    try:
        file_path = request.get("file_path")
        speaker_track_mapping = request.get("speaker_track_mapping", {})
        existing_speakers = request.get("existing_speakers")
        existing_subtitles = request.get("existing_subtitles")
        track_assignments = request.get("track_assignments", {})

        logger.info(f"ğŸ­ íŠ¸ë™ ë°°ì¹˜ ìš”ì²­ ë°›ìŒ")
        logger.info(f"  - file_path: {file_path}")
        logger.info(f"  - speaker_track_mapping: {speaker_track_mapping}")
        logger.info(f"  - track_assignments: {track_assignments}")
        logger.info(f"  - ê¸°ì¡´ í™”ì: {bool(existing_speakers)}")
        logger.info(f"  - ê¸°ì¡´ ìë§‰: {bool(existing_subtitles) and len(existing_subtitles) if existing_subtitles else 0}")

        # ê¸°ì¡´ í™”ì ì¸ì‹ ê²°ê³¼ ì‚¬ìš©
        if existing_speakers and existing_subtitles:
            logger.info("ğŸ­ ê¸°ì¡´ ìŒì„± ê¸°ë°˜ í™”ì ì¸ì‹ ê²°ê³¼ ì‚¬ìš©")
            speakers = existing_speakers
            subtitles = existing_subtitles
        elif file_path and os.path.exists(file_path):
            logger.info("ğŸ­ ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ ê¸°ë°˜ í™”ì ì¸ì‹ ìˆ˜í–‰")
            # SRT íŒŒì¼ íŒŒì‹±
            subtitles = parse_srt_file(file_path)

            # í™”ì ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            speaker_recognition = SpeakerRecognition()

            # í™”ì ê°ì§€
            detection_result = speaker_recognition.detect_speakers_from_subtitles(subtitles)
            speakers = detection_result["speakers"]
        else:
            raise HTTPException(status_code=400, detail="ê¸°ì¡´ í™”ì/ìë§‰ ë°ì´í„° ë˜ëŠ” SRT íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤")

        # ì‚¬ìš©ì ì§€ì • í™”ì(í™”ì4)ëŠ” ìë™ ë¶„ë¥˜ ëŒ€ìƒì—ì„œ ì œì™¸í•˜ê¸° ìœ„í•œ ì¤€ë¹„
        if speakers and 'í™”ì4' in speakers:
            logger.info('ğŸ¯ í™”ì4ëŠ” ì‚¬ìš©ì ì§€ì •ìš©ìœ¼ë¡œ í†µê³„ë§Œ ì´ˆê¸°í™”')
            speaker4_info = speakers['í™”ì4']
            speaker4_info['subtitle_count'] = 0
            speaker4_info['subtitle_indices'] = []
            speaker4_info['total_duration'] = 0
            speaker4_info['total_chars'] = 0
            speaker4_info['avg_duration'] = 0
            speaker4_info['avg_chars'] = 0
            speaker4_info['sample_texts'] = []

        # ìë§‰ì„ íŠ¸ë™ë³„ë¡œ ë¶„ë¥˜
        classified_subtitles = {
            "main": [],
            "translation": [],
            "description": [],
            "unassigned": []
        }

        # track_assignmentsê°€ ìˆìœ¼ë©´ ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ë¶„ë¥˜
        if track_assignments:
            logger.info(f"ğŸ¯ ì¸ë±ìŠ¤ ê¸°ë°˜ íŠ¸ë™ í• ë‹¹ ì²˜ë¦¬: {track_assignments}")

            # ëª¨ë“  ìë§‰ì„ ë¨¼ì € unassignedë¡œ ì´ˆê¸°í™”
            for i, subtitle in enumerate(subtitles):
                subtitle['assigned_track'] = 'unassigned'
                subtitle['global_index'] = i
                classified_subtitles['unassigned'].append(subtitle)

            # track_assignmentsì— ë”°ë¼ ìë§‰ì„ í•´ë‹¹ íŠ¸ë™ìœ¼ë¡œ ì´ë™
            for track, indices in track_assignments.items():
                if track in classified_subtitles:
                    for idx in indices:
                        # unassignedì—ì„œ í•´ë‹¹ ìë§‰ ì°¾ì•„ì„œ ì´ë™
                        for i, subtitle in enumerate(classified_subtitles['unassigned']):
                            if subtitle.get('global_index') == idx:
                                # unassignedì—ì„œ ì œê±°í•˜ê³  í•´ë‹¹ íŠ¸ë™ì— ì¶”ê°€
                                subtitle['assigned_track'] = track
                                classified_subtitles['unassigned'].pop(i)
                                classified_subtitles[track].append(subtitle)
                                break
        else:
            # ê¸°ì¡´ speaker_track_mapping ë°©ì‹ ì‚¬ìš©
            if not speaker_track_mapping:
                # ê¸°ë³¸ íŠ¸ë™ í• ë‹¹ (í™”ì1 -> main, í™”ì2 -> translation, í™”ì3 -> description)
                # í™”ì4ëŠ” ì‚¬ìš©ììš©ìœ¼ë¡œ ìë™ ë°°ì¹˜ì—ì„œ ì œì™¸í•˜ì—¬ ë¯¸ë¶„ë¥˜ë¡œ ìœ ì§€
                speaker_track_mapping = {}
                speaker_names = list(speakers.keys())
                for i, speaker in enumerate(speaker_names):
                    if speaker == 'í™”ì4':
                        speaker_track_mapping[speaker] = "unassigned"
                        continue
                    elif i == 0:
                        speaker_track_mapping[speaker] = "main"
                    elif i == 1:
                        speaker_track_mapping[speaker] = "translation"
                    else:
                        speaker_track_mapping[speaker] = "description"

                # ë¯¸ë¶„ë¥˜ì™€ í™”ì3ë„ ì„¤ëª… íŠ¸ë™ìœ¼ë¡œ ê¸°ë³¸ ì„¤ì •
                speaker_track_mapping['ë¯¸ë¶„ë¥˜'] = "description"
                speaker_track_mapping['í™”ì3'] = "description"

            # ì‚¬ìš©ì ì„¤ì • ë§¤í•‘ì—ë„ ê³µí†µ ê·œì¹™ ì ìš©
            if 'ë¯¸ë¶„ë¥˜' not in speaker_track_mapping:
                speaker_track_mapping['ë¯¸ë¶„ë¥˜'] = "description"
            if 'í™”ì3' not in speaker_track_mapping:
                speaker_track_mapping['í™”ì3'] = "description"
            # í™”ì4ëŠ” í•­ìƒ ì‚¬ìš©ì ì§€ì •ìš©ìœ¼ë¡œ ìœ ì§€
            speaker_track_mapping['í™”ì4'] = "unassigned"

            logger.info(f"ğŸ­ í™”ì-íŠ¸ë™ ë§¤í•‘: {speaker_track_mapping}")

            # ìë§‰ì„ í™”ìë³„ë¡œ ë¶„ë¥˜ - ê¸°ì¡´ speaker_id ì‚¬ìš©
            speaker_name_counts = {}
            for subtitle in subtitles:
                speaker_name = subtitle.get('speaker_name', 'ë¯¸ë¶„ë¥˜')

                # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ Noneì¸ ê²½ìš° ë¯¸ë¶„ë¥˜ë¡œ ì²˜ë¦¬
                if not speaker_name or speaker_name.strip() == '':
                    speaker_name = 'ë¯¸ë¶„ë¥˜'

                # í™”ì4ëŠ” ì‚¬ìš©ì ì§€ì •ìš©ìœ¼ë¡œ ìë™ ë¶„ë¥˜ì—ì„œ ì œì™¸
                if speaker_name == 'í™”ì4':
                    subtitle['original_speaker_name'] = 'í™”ì4'
                    subtitle['speaker_name'] = 'ë¯¸ë¶„ë¥˜'
                    subtitle['assigned_track'] = 'unassigned'
                    classified_subtitles['unassigned'].append(subtitle)
                    speaker_name_counts['ë¯¸ë¶„ë¥˜'] = speaker_name_counts.get('ë¯¸ë¶„ë¥˜', 0) + 1
                    continue

                assigned_track = speaker_track_mapping.get(speaker_name, 'description')  # defaultë¥¼ descriptionìœ¼ë¡œ ë³€ê²½
                subtitle['assigned_track'] = assigned_track
                subtitle['speaker_name'] = speaker_name  # ì •ê·œí™”ëœ speaker_name ë‹¤ì‹œ ì €ì¥
                classified_subtitles[assigned_track].append(subtitle)

                # í™”ì ì´ë¦„ í†µê³„
                speaker_name_counts[speaker_name] = speaker_name_counts.get(speaker_name, 0) + 1

            # í™”ì ì´ë¦„ ë¶„í¬ ë¡œê¹…
            logger.info(f"ğŸ­ í™”ì ì´ë¦„ ë¶„í¬:")
            for speaker, count in speaker_name_counts.items():
                mapped_track = speaker_track_mapping.get(speaker, 'unassigned')
                logger.info(f"  {speaker}: {count}ê°œ â†’ {mapped_track} íŠ¸ë™")

        # Convert numpy types to native Python types for JSON serialization
        def convert_numpy_types(obj):
            """Convert numpy types to native Python types recursively"""
            if hasattr(obj, 'item'):  # numpy scalar
                return obj.item()
            elif hasattr(obj, 'tolist'):  # numpy array
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: convert_numpy_types(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            else:
                return obj

        # Convert all data to be JSON serializable
        speakers_serializable = convert_numpy_types(speakers)
        classified_subtitles_serializable = convert_numpy_types(classified_subtitles)

        # ìì„¸í•œ track_counts ë¡œê¹…
        track_counts = {}
        total_subtitles = 0
        for track, subs in classified_subtitles.items():
            count = len(subs)
            track_counts[track] = count
            total_subtitles += count
            logger.info(f"  {track} íŠ¸ë™: {count}ê°œ ìë§‰")

        logger.info(f"ğŸ¯ ì´ ìë§‰ ìˆ˜: {total_subtitles}ê°œ")
        logger.info(f"ğŸ¯ ì…ë ¥ ìë§‰ ìˆ˜: {len(subtitles)}ê°œ")

        return {
            "status": "success",
            "file": file_path,
            "speakers": speakers_serializable,
            "speaker_track_mapping": speaker_track_mapping,
            "classified_subtitles": classified_subtitles_serializable,
            "track_counts": track_counts
        }

    except Exception as e:
        logger.exception(f"í™”ì íŠ¸ë™ í• ë‹¹ ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analysis/audio-speaker-recognition")
async def analyze_audio_speakers(request: dict = Body(...)):
    """ìŒì„± íŒŒì¼ì—ì„œ í™”ì ì¸ì‹ ë° ë¶„ë¥˜"""
    audio_path = None
    srt_path = None

    try:
        logger.info(f"ğŸµ ìŒì„± ê¸°ë°˜ í™”ì ì¸ì‹ API í˜¸ì¶œ - ìš”ì²­: {request}")

        audio_path = request.get("audio_path")
        srt_path = request.get("srt_path")  # ì„ íƒì 
        n_speakers = request.get("n_speakers")  # ì„ íƒì 

        logger.info(f"ğŸµ íŒŒì¼ ê²½ë¡œ - ì˜¤ë””ì˜¤: {audio_path}, SRT: {srt_path}")

        if not audio_path or not os.path.exists(audio_path):
            logger.error(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {audio_path}")
            return {
                "status": "error",
                "audio_file": audio_path,
                "srt_file": srt_path,
                "error": "ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                "speakers": {},
                "total_speakers": 0
            }

        # ìë§‰ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ
        subtitles = None
        if srt_path and os.path.exists(srt_path) and srt_path.endswith('.srt'):
            logger.info(f"ğŸµ SRT íŒŒì¼ ë¡œë“œ ì¤‘: {srt_path}")
            subtitles = parse_srt_file(srt_path)
            logger.info(f"ğŸµ SRT ìë§‰ ê°œìˆ˜: {len(subtitles) if subtitles else 0}")

        # ê³ ê¸‰ ìŒì„± ê¸°ë°˜ í™”ì ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (scikit-learn ì‚¬ìš©)
        logger.info("ğŸµ AudioSpeakerRecognition ì´ˆê¸°í™” ì¤‘...")
        audio_recognition = AudioSpeakerRecognition()

        # í™”ì ì¸ì‹ ìˆ˜í–‰
        logger.info("ğŸµ ê³ ê¸‰ í™”ì ì¸ì‹ ìˆ˜í–‰ ì‹œì‘...")
        result = audio_recognition.recognize_speakers_from_audio(
            audio_path=audio_path,
            subtitles=subtitles,
            n_speakers=n_speakers
        )

        logger.info(f"ğŸµ í™”ì ì¸ì‹ ê²°ê³¼: {result}")

        # Convert numpy types to native Python types for JSON serialization
        def convert_numpy_types(obj):
            """Convert numpy types to native Python types recursively"""
            if hasattr(obj, 'item'):  # numpy scalar
                return obj.item()
            elif hasattr(obj, 'tolist'):  # numpy array
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: convert_numpy_types(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            else:
                return obj

        # Convert result to be JSON serializable
        result_serializable = convert_numpy_types(result)

        return {
            "status": "success",
            "audio_file": audio_path,
            "srt_file": srt_path,
            **result_serializable
        }

    except Exception as e:
        logger.exception(f"âŒ ìŒì„± ê¸°ë°˜ í™”ì ì¸ì‹ ì¹˜ëª…ì  ì—ëŸ¬: {e}")
        return {
            "status": "error",
            "audio_file": audio_path or "unknown",
            "srt_file": srt_path or "unknown",
            "error": str(e),
            "speakers": {},
            "total_speakers": 0
        }


@router.post("/analysis/extract-speaker-audio")
async def extract_speaker_audio_segments(request: dict = Body(...)):
    """í™”ìë³„ë¡œ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬"""
    try:
        audio_path = request.get("audio_path")
        srt_path = request.get("srt_path")
        output_dir = request.get("output_dir")

        if not audio_path or not os.path.exists(audio_path):
            raise HTTPException(status_code=404, detail="ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # ìŒì„± ê¸°ë°˜ í™”ì ì¸ì‹ ìˆ˜í–‰
        audio_recognition = AudioSpeakerRecognition()

        # ìë§‰ì´ ìˆìœ¼ë©´ ë¡œë“œ
        subtitles = None
        if srt_path and os.path.exists(srt_path):
            subtitles = parse_srt_file(srt_path)

        # í™”ì ì¸ì‹
        recognition_result = audio_recognition.recognize_speakers_from_audio(
            audio_path=audio_path,
            subtitles=subtitles
        )

        if "error" in recognition_result:
            raise HTTPException(status_code=500, detail=recognition_result["error"])

        # í•„ìš”í•œ íŠ¹ì„±ê³¼ ë¼ë²¨ ì¬ì¶”ì¶œ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ìºì‹œ ì‚¬ìš© ê¶Œì¥)
        features = audio_recognition.extract_audio_features(audio_path)
        speaker_labels = audio_recognition.cluster_speakers(features)

        # í™”ìë³„ ì˜¤ë””ì˜¤ ë¶„ë¦¬
        speaker_files = audio_recognition.extract_speaker_segments(
            audio_path=audio_path,
            speaker_labels=speaker_labels,
            features=features,
            output_dir=output_dir
        )

        return {
            "status": "success",
            "audio_file": audio_path,
            "speaker_files": speaker_files,
            "speakers": recognition_result.get("speakers", {}),
            "total_speakers": recognition_result.get("total_speakers", 0)
        }

    except Exception as e:
        logger.exception(f"í™”ìë³„ ì˜¤ë””ì˜¤ ë¶„ë¦¬ ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analysis/reinterpret")
async def reinterpret_subtitles(request: dict = Body(...)):
    """ëŒ€ì‚¬ ë° ì„¤ëª… ìë§‰ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë‚´ë ˆì´ì…˜ ì¬í•´ì„ ìƒì„±"""
    try:
        dialogues = request.get("dialogue_subtitles") or []
        descriptions = request.get("description_subtitles") or []

        if not dialogues and not descriptions:
            raise HTTPException(status_code=400, detail="ì¬í•´ì„í•  ìë§‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

        metadata = request.get("metadata") or {}
        tone = metadata.get("tone")

        reinterpretation_result = ai_reinterpret_subtitles(dialogues, descriptions, tone=tone)

        response = {"status": "success", **reinterpretation_result}
        logger.info(
            "ì¬í•´ì„ ì™„ë£Œ - ëŒ€ì‚¬ %dê°œ, ì„¤ëª… %dê°œ",
            len(dialogues),
            len(descriptions),
        )
        return response

    except HTTPException:
        raise
    except ValueError as exc:
        logger.warning("ì¬í•´ì„ ì…ë ¥ ì˜¤ë¥˜: %s", exc)
        raise HTTPException(status_code=400, detail=str(exc))
    except Exception as exc:
        logger.exception("ì¬í•´ì„ ì²˜ë¦¬ ì‹¤íŒ¨: %s", exc)
        detail_message = str(exc).strip() or "ì¬í•´ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
        raise HTTPException(status_code=500, detail=detail_message)
